{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r:\\\\Attendance_system'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_122444\\339632063.py:5: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  model = keras.models.load_model(\"artifacts\\model.keras\", custom_objects={'scaling': scaling})\n"
     ]
    }
   ],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "def scaling(x, scale=1.0):\n",
    "    return x * scale\n",
    "\n",
    "model = keras.models.load_model(\"artifacts\\model.keras\", custom_objects={'scaling': scaling})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "def scaling(x, scale=1.0):\n",
    "    return x * scale\n",
    "\n",
    "# Load the model\n",
    "model_inference = keras.models.load_model(\"artifacts/model.keras\", custom_objects={'scaling': scaling})\n",
    "\n",
    "class Predictions:\n",
    "    def __init__(self, image_path, model=model_inference):\n",
    "        self.image_path = image_path\n",
    "        self.model = model\n",
    "        self.input_size = (160, 160)\n",
    "        \n",
    "    def preprocess_image(self):\n",
    "        image = Image.open(self.image_path).convert(\"RGB\")\n",
    "        image = image.resize(self.input_size, Image.LANCZOS)\n",
    "        image_array = np.array(image) / 255.0\n",
    "        image_array = np.expand_dims(image_array, axis=0)\n",
    "        return image_array\n",
    "    \n",
    "    def predict(self):\n",
    "        preprocessed_image = self.preprocess_image()\n",
    "        prediction = self.model.predict(preprocessed_image)\n",
    "        predicted_class = np.argmax(prediction)\n",
    "        return predicted_class\n",
    "\n",
    "# present = []\n",
    "\n",
    "# # Example usage\n",
    "# for files in os.listdir(\"artifacts/testing_images\"):\n",
    "#     image_path = f\"artifacts/testing_images/{files}\"\n",
    "#     pred = Predictions(image_path)\n",
    "#     present.append(pred.predict())\n",
    "    \n",
    "# label = {0:\"Ben\",1:\"Rahul\",2:\"Santhosh\",3:\"Naveen\"}\n",
    "# mapped_names = [label[i] for i in present]\n",
    "# print(mapped_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "['Ben', 'Naveen', 'Rahul', 'Santhosh']\n"
     ]
    }
   ],
   "source": [
    "def present_names():\n",
    "    present = []\n",
    "    \n",
    "    for files in os.listdir(\"artifacts/testing_images\"):\n",
    "        image_path = f\"artifacts/testing_images/{files}\"\n",
    "        pred = Predictions(image_path)\n",
    "        present.append(pred.predict())\n",
    "    label = {0:\"Ben\",1:\"Rahul\",2:\"Santhosh\",3:\"Naveen\"}\n",
    "    mapped_names = [label[i] for i in present]\n",
    "    return mapped_names\n",
    "\n",
    "names = present_names()\n",
    "print(names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SyntaxWarning: invalid escape sequence '\\m'\n",
      "SyntaxWarning: invalid escape sequence '\\m'\n",
      "SyntaxWarning: invalid escape sequence '\\m'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "['Ben', 'Naveen', 'Rahul', 'Santhosh']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "class Predictions:\n",
    "    def __init__(self,model_path,image_path = None):\n",
    "        self.image_path = image_path\n",
    "        self.model_path = model_path\n",
    "        self.input_size = (160, 160)\n",
    "        \n",
    "    def preprocess_image(self):\n",
    "        image = Image.open(self.image_path).convert(\"RGB\")\n",
    "        image = image.resize(self.input_size, Image.LANCZOS)\n",
    "        image_array = np.array(image) / 255.0\n",
    "        image_array = np.expand_dims(image_array, axis=0)\n",
    "        return image_array\n",
    "    \n",
    "    @keras.saving.register_keras_serializable()\n",
    "    def scaling(x, scale=1.0):\n",
    "        return x * scale\n",
    "    \n",
    "    def predict(self):\n",
    "        self.model = keras.models.load_model(self.model_path, custom_objects={'scaling': scaling})\n",
    "        preprocessed_image = self.preprocess_image()\n",
    "        prediction = self.model.predict(preprocessed_image)\n",
    "        predicted_class = np.argmax(prediction)\n",
    "        return predicted_class\n",
    "    \n",
    "    def names(self, directory):\n",
    "        present = []\n",
    "        \n",
    "        for files in os.listdir(directory):\n",
    "            image_path = os.path.join(directory, files)\n",
    "            self.image_path = image_path  # Update image path for prediction\n",
    "            present.append(self.predict())\n",
    "            \n",
    "        label = {0: \"Ben\", 1: \"Rahul\", 2: \"Santhosh\", 3: \"Naveen\"}\n",
    "        mapped_names = [label[i] for i in present]\n",
    "        return mapped_names\n",
    "\n",
    "# Example usage:\n",
    "predictions = Predictions(model_path = \"artifacts\\model.keras\")\n",
    "print(predictions.names(\"artifacts/testing_images\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Ben', 'Naveen', 'Rahul', 'Santhosh']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "class Predictions:\n",
    "    @keras.saving.register_keras_serializable()\n",
    "    def scaling(x, scale=1.0):\n",
    "        return x * scale\n",
    "\n",
    "    def __init__(self, model_path,image_path = None):\n",
    "        self.image_path = image_path\n",
    "        self.model_path = model_path\n",
    "        self.model = keras.models.load_model(model_path, custom_objects={'scaling': scaling})\n",
    "        self.input_size = (160, 160)\n",
    "        \n",
    "    def preprocess_image(self):\n",
    "        image = Image.open(self.image_path).convert(\"RGB\")\n",
    "        image = image.resize(self.input_size, Image.LANCZOS)\n",
    "        image_array = np.array(image) / 255.0\n",
    "        image_array = np.expand_dims(image_array, axis=0)\n",
    "        return image_array\n",
    "    \n",
    "    def predict(self):\n",
    "        preprocessed_image = self.preprocess_image()\n",
    "        prediction = self.model.predict(preprocessed_image)\n",
    "        predicted_class = np.argmax(prediction)\n",
    "        return predicted_class\n",
    "    \n",
    "    def names(self, directory = \"R:/Attendance_system/artifacts/testing_images\"):\n",
    "        present = []\n",
    "        \n",
    "        for files in os.listdir(directory):\n",
    "            image_path = os.path.join(directory, files)\n",
    "            self.image_path = image_path  # Update image path for prediction\n",
    "            present.append(self.predict())\n",
    "            \n",
    "        label = {0: \"Ben\", 1: \"Rahul\", 2: \"Santhosh\", 3: \"Naveen\"}\n",
    "        mapped_names = [label[i] for i in present]\n",
    "        return mapped_names\n",
    "\n",
    "# Example usage:\n",
    "predictions = Predictions(\"artifacts/model.keras\")\n",
    "predictions.names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "2\n",
      "Image: artifacts/testing_images/santhosh_box_0.png, Predicted Class: 2\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# import tensorflow as tf\n",
    "\n",
    "# image_path = \"artifacts/testing_images/santhosh_box_0.png\"\n",
    "# input_size = (160, 160)  \n",
    "\n",
    "# def preprocess_image(image_path):\n",
    "#     image = Image.open(image_path).convert(\"RGB\")\n",
    "#     image = image.resize(input_size, Image.LANCZOS)\n",
    "#     image = image.convert(\"RGB\")\n",
    "#     image_array = np.array(image) / 255.0\n",
    "#     image_array = np.expand_dims(image_array, axis=0)\n",
    "#     return image_array\n",
    "\n",
    "# preprocessed_image = preprocess_image(image_path)\n",
    "# prediction = model.predict(preprocessed_image)\n",
    "# predicted_class = np.argmax(prediction)\n",
    "# print(predicted_class)\n",
    "# print(f\"Image: {image_path}, Predicted Class: {predicted_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
