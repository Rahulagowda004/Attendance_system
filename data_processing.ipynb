{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images for rahul\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:94: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0x46dff480::Set<3,4,-1>,struct cv::impl::A0x46dff480::Set<0,2,5>,4>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Unsupported depth of input image:\n>     'VDepth::contains(depth)'\n> where\n>     'depth' is 6 (CV_64F)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 72\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Run the preprocessing on the entire dataset\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[43mpreprocess_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 61\u001b[0m, in \u001b[0;36mpreprocess_dataset\u001b[1;34m(dataset_path)\u001b[0m\n\u001b[0;32m     58\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(person_path, img_name)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Preprocess the image\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m processed_image \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m processed_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Save preprocessed image as a numpy array for later use\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(person_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessed_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 40\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     37\u001b[0m     face_image \u001b[38;5;241m=\u001b[39m face_image \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Convert to RGB format for FaceNet\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     face_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m face_image\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:94: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0x46dff480::Set<3,4,-1>,struct cv::impl::A0x46dff480::Set<0,2,5>,4>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Unsupported depth of input image:\n>     'VDepth::contains(depth)'\n> where\n>     'depth' is 6 (CV_64F)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "# Set the dataset path and target size for FaceNet\n",
    "dataset_path = \"dataset_directory\"\n",
    "target_size = (160, 160)  # FaceNet expects 160x160 pixel input\n",
    "\n",
    "# Initialize the MTCNN detector for face alignment\n",
    "detector = MTCNN()\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error reading {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Detect faces\n",
    "    result = detector.detect_faces(image)\n",
    "    \n",
    "    if result:\n",
    "        # Assume the first face detected is the target face\n",
    "        face = result[0]\n",
    "        x, y, width, height = face['box']\n",
    "        x, y = max(0, x), max(0, y)\n",
    "\n",
    "        # Crop the face region\n",
    "        face_image = image[y:y+height, x:x+width]\n",
    "        \n",
    "        # Resize to target size (160x160)\n",
    "        face_image = cv2.resize(face_image, target_size)\n",
    "        \n",
    "        # Normalize pixel values to [0, 1]\n",
    "        face_image = face_image / 255.0\n",
    "        \n",
    "        # Convert to RGB format for FaceNet\n",
    "        face_image = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        return face_image\n",
    "    else:\n",
    "        print(f\"No face detected in {image_path}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_dataset(dataset_path):\n",
    "    for person_name in os.listdir(dataset_path):\n",
    "        person_path = os.path.join(dataset_path, person_name)\n",
    "        \n",
    "        # Only proceed if it's a directory\n",
    "        if not os.path.isdir(person_path):\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing images for {person_name}\")\n",
    "        \n",
    "        for img_name in os.listdir(person_path):\n",
    "            img_path = os.path.join(person_path, img_name)\n",
    "            \n",
    "            # Preprocess the image\n",
    "            processed_image = preprocess_image(img_path)\n",
    "            \n",
    "            if processed_image is not None:\n",
    "                # Save preprocessed image as a numpy array for later use\n",
    "                save_path = os.path.join(person_path, f\"processed_{img_name}\")\n",
    "                np.save(save_path, processed_image)\n",
    "                print(f\"Saved processed image at {save_path}\")\n",
    "            else:\n",
    "                print(f\"Skipping {img_path}\")\n",
    "\n",
    "# Run the preprocessing on the entire dataset\n",
    "preprocess_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
